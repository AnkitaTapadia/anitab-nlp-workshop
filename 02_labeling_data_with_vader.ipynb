{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labeling Data with VADER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data used in this tutorial has been scraped from Twitter using [Twint](https://github.com/twintproject/twint), an advanced Twitter scraping tool written in Python. It has then been partially cleaned, and labeled for negativity and positivity using VADER (Valence Aware Dictionary for Sentiment Reasoning) model, which is part of the Natural Language Toolkit (NLTK) library. VADER can be used for sentiment analysis that is sensitive to both polarity (positive/negative) and intensity (strength) of emotion. It is available in the NLTK package and can be applied directly to unlabeled text data. Below are the steps showing the labeling. \n",
    "\n",
    "\n",
    "**Natural Language is a difficult problem.** One of the most challenging aspects of working in supervised Machine Learning and/or Deep Learning is to have good data. Good data can mean many things in different contexts. Labeling data is an expensive process and is not free from human bias. The dataset and labels created for it in this tutorial are far from being perfect. \n",
    "\n",
    "**A more sophisticated labeling approach needs to be applied** to get more accurate labels, which often requires a human-in-the-loop approach. However, for our purposes in this tutorial which aim introducting participants to basic concepts of NLP, we decided to put our focus less on the accuracy of the model (or the labels), and more on the steps to an end-to-end model. We believe that better data beats better algorithms, and those, who would like to experiment more, would need to iterate over the preparation and cleaning of data and try out more sophisticated models to achieve better accuracy.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('<the_data_file_you_want_to_label>.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk import sentiment\n",
    "\n",
    "sentiment_analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "#The data we collected from Twitter, had a `tweet` column. It is the column we want to label on.\n",
    "df['scores'] = df['tweet'].apply(lambda tweet: sentiment_analyzer.polarity_scores(tweet))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **We will clean the tweets that are replies to other people from usernames that they came with**\n",
    "\n",
    "+ Usernames in tweet replies starts with an @ symbol. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x: ' '.join([item for item in x.split() if not item.startswith('@')])\n",
    "df[\"tweet\"] = df[\"tweet\"].apply(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **We will also remove any urls in tweets to reduce noise in data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_urls = lambda x: ' '.join([item for item in x.split() if not item.startswith('https://')])\n",
    "df[\"tweet\"] = df[\"tweet\"].apply(remove_urls)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `compound` **in VADER, is computed by normalizing the scores of positive, negative, and neutral**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['compound']  = df['scores'].apply(lambda score_dict: score_dict['compound'])\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **We apply a simple approach here when we decide which sentiment is negative or positive**\n",
    "\n",
    "+ You would probably want to spend more time on how to make this decision. For now, we will keep it simple. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'] = df['compound'].apply(lambda c: 'pos' if c >= 0 else 'neg')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['tweet', 'sentiment']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Save your labeled data into a csv file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('<your_file_name>.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
